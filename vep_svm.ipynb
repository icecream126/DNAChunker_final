{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db878bc1",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from os import path as osp\n",
    "\n",
    "import fsspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_TO_TSS = [[0, 30_000], [30_000, 100_000], [100_000, np.infty]]\n",
    "USE_TISSUE = [True]  # used as another for loop for fitting SVM, whether to use tissue embed or not\n",
    "Cs = [1, 5, 10]  # for loop in fitting SVM, inverse of L2 penalty (sklearn hyperparam)\n",
    "PATH_TO_OUTPUTS = \"./outputs/downstream/vep_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c58437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fsspec_exists(filename: str) -> bool:\n",
    "    \"\"\"Check if file exists in manner compatible with fsspec.\"\"\"\n",
    "    fs, _ = fsspec.core.url_to_fs(filename)\n",
    "    return fs.exists(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18522e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_nan_filter(data: dict, data_key: str) -> dict:\n",
    "    \"\"\"Filter any items that have NaN in embedding within TSS bucket\"\"\"\n",
    "    mask_out = torch.logical_or(\n",
    "        torch.any(data[data_key].isnan(), dim=1),\n",
    "        torch.any(data[f\"rc_{data_key}\"].isnan(), dim=1)\n",
    "    )\n",
    "    \n",
    "    new_data = dict()\n",
    "    for data_key in data.keys():\n",
    "        new_data[data_key] = data[data_key][~mask_out]\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def dataset_tss_filter(data: dict, min_distance: int, max_distance: int) -> dict:\n",
    "    \"\"\"Filter the data to items that fall within TSS bucket\"\"\"\n",
    "    distance_mask = ((data[\"distance_to_nearest_tss\"] >= min_distance) \n",
    "                     & (data[\"distance_to_nearest_tss\"] <= max_distance))\n",
    "    new_data = dict()\n",
    "    for data_key in data.keys():\n",
    "        new_data[data_key] = data[data_key][distance_mask]\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d1006",
   "metadata": {},
   "source": [
    "## Specify which models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629cb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embeddings to test\n",
    "model_dict = {\n",
    "    \"HyenaDNA\": dict(\n",
    "        embed_path=\"hyena_downstream-seqlen=131k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=False,\n",
    "        conjoin_test=False,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "    \"Caduceus-Ph\": dict(\n",
    "        embed_path=\"caduceus-ph_downstream-seqlen=131k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=False,\n",
    "        conjoin_test=True,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "    \"Caduceus w/o Equiv.\": dict(\n",
    "        embed_path=\"caduceus-ph_downstream-seqlen=131k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=False,\n",
    "        conjoin_test=False,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "    \"Caduceus-PS\": dict(\n",
    "        embed_path=\"caduceus-ps_downstream-seqlen=131k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=True,\n",
    "        conjoin_test=False,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "    \"Enformer\": dict(\n",
    "        embed_path=\"enformer-seqlen=196k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=False,\n",
    "        conjoin_test=False,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "    \"NTv2\": dict(\n",
    "        embed_path=\"NTv2_downstream-seqlen=12k\",\n",
    "        rc_aug=False,\n",
    "        conjoin_train=False,\n",
    "        conjoin_test=False,\n",
    "        key=\"concat_avg_ws\",\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e64367",
   "metadata": {},
   "source": [
    "## Fit and test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaeb519-5c35-4fba-a09b-2d47c122320d",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"model_name\": [],\n",
    "    \"bucket_id\": [],\n",
    "    \"use_tissue\": [],\n",
    "    \"C\": [],\n",
    "    \"seed\": [],\n",
    "    \"AUROC\": [],\n",
    "}\n",
    "\n",
    "for model_name, downstream_kwargs in model_dict.items():\n",
    "    print(f\"********** Gathering results for: {model_name} **********\")\n",
    "    embed_path = downstream_kwargs[\"embed_path\"]\n",
    "    rc_aug = downstream_kwargs[\"rc_aug\"]\n",
    "    conjoin_train = downstream_kwargs[\"conjoin_train\"]\n",
    "    conjoin_test = downstream_kwargs[\"conjoin_test\"]\n",
    "    key = downstream_kwargs[\"key\"]\n",
    "    \n",
    "    if \"NT\" in model_name: assert (rc_aug == False) and (conjoin_train == False) and (conjoin_test == False)\n",
    "    \n",
    "    base_embeds_path = PATH_TO_OUTPUTS\n",
    "    embeds_path = osp.join(base_embeds_path, embed_path)\n",
    "    \n",
    "    print(f\"Embed Path: {embeds_path}\")\n",
    "    with fsspec.open(osp.join(embeds_path, \"train_embeds_combined.pt\"), \"rb\") as f:\n",
    "        train_val_ds_raw = torch.load(f, map_location=\"cpu\")\n",
    "        train_val_ds_raw = dataset_nan_filter(train_val_ds_raw, data_key=key)\n",
    "    with fsspec.open(osp.join(embeds_path, \"test_embeds_combined.pt\"), \"rb\") as f:\n",
    "        test_ds_raw = torch.load(f, map_location=\"cpu\")\n",
    "        test_ds_raw = dataset_nan_filter(test_ds_raw, data_key=key)\n",
    "    print(f\"Total Train size: {len(train_val_ds_raw[key])},\", end=\" \")\n",
    "    print(f\"Total Test size: {len(test_ds_raw[key])},\", end=\" \")\n",
    "    print(f\"Shape: {test_ds_raw[key].shape[1:]}\")\n",
    "\n",
    "\n",
    "    for bucket_id, (min_dist, max_dist) in enumerate(DIST_TO_TSS):\n",
    "        # Filter data to desired TSS bucket\n",
    "        train_val_ds_filter = dataset_tss_filter(train_val_ds_raw, min_dist, max_dist)\n",
    "        test_ds_filter = dataset_tss_filter(test_ds_raw, min_dist, max_dist)\n",
    "        print(f\"- TSS bucket: [{min_dist}, {max_dist}],\", end=\" \")\n",
    "        print(f\"Train size: {len(train_val_ds_filter[key])},\", end=\" \")\n",
    "        print(f\"Test size: {len(test_ds_filter[key])}\")\n",
    "    \n",
    "        for use_tissue in USE_TISSUE:\n",
    "            for C in Cs:\n",
    "                for seed in range(1, 6):     \n",
    "                    # Re-seed for SVM fitting\n",
    "                    random.seed(seed)\n",
    "                    np.random.seed(seed)\n",
    "                    torch.manual_seed(seed)\n",
    "                    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "                    svm_clf = make_pipeline(\n",
    "                        StandardScaler(),\n",
    "                        SVC(C=C, random_state=seed),\n",
    "                    )\n",
    "\n",
    "                    # Setup Train/Test dataset\n",
    "                    if conjoin_train:\n",
    "                        X = np.array(train_val_ds_filter[key])\n",
    "                        X += np.array(train_val_ds_filter[f\"rc_{key}\"])\n",
    "                        X /= 2\n",
    "                    else:\n",
    "                        X = np.array(train_val_ds_filter[key])\n",
    "                    X_with_tissue = np.concatenate(\n",
    "                        [X, np.array(train_val_ds_filter[\"tissue_embed\"])[..., None]],\n",
    "                        axis=-1\n",
    "                    )\n",
    "                    y = train_val_ds_filter[\"labels\"]\n",
    "                    if conjoin_train or conjoin_test:\n",
    "                        X_test = np.array(test_ds_filter[key])\n",
    "                        X_test += np.array(test_ds_filter[f\"rc_{key}\"])\n",
    "                        X_test /= 2\n",
    "                    else:\n",
    "                        X_test = np.array(test_ds_filter[key])\n",
    "                    X_test_with_tissue = np.concatenate(\n",
    "                        [X_test, np.array(test_ds_filter[\"tissue_embed\"])[..., None]],\n",
    "                        axis=-1\n",
    "                    )\n",
    "                    y_test = test_ds_filter[\"labels\"]\n",
    "\n",
    "                    print(f\"\\tFitting SVM ({use_tissue=}, {C=}, {seed=})...\", end=\" \")\n",
    "                    \n",
    "                    mask = np.random.choice(len(X), size=5000, replace= 5000 > len(X) )\n",
    "                    if use_tissue: \n",
    "                        X_train = X_with_tissue[mask]\n",
    "                        X_test = X_test_with_tissue\n",
    "                    else: \n",
    "                        X_train = X[mask]\n",
    "                    y_train = y[mask]\n",
    "\n",
    "                    start = time.time()\n",
    "                    svm_clf.fit(X_train, y_train)\n",
    "                    svm_y_pred = svm_clf.predict(X_test)\n",
    "                    svm_aucroc = roc_auc_score(y_test, svm_y_pred)\n",
    "                    end = time.time()\n",
    "                    print(f\"Completed! ({end - start:0.3f} s) -\", end=\" \")\n",
    "                    print(f\"AUROC: {svm_aucroc}\")\n",
    "                     \n",
    "                    metrics[\"model_name\"] += [model_name]\n",
    "                    metrics[\"bucket_id\"] += [bucket_id]\n",
    "                    metrics[\"use_tissue\"] += [use_tissue]\n",
    "                    metrics[\"C\"] += [C]\n",
    "                    metrics[\"seed\"] += [seed]\n",
    "                    metrics[\"AUROC\"] += [svm_aucroc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(metrics)\n",
    "df_metrics.to_csv(osp.join(PATH_TO_OUTPUTS, \"SVM_results.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e06a25",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_replacement = {\n",
    "    \"Caduceus w/o Equiv.\": \"Caduceus w/o\\nEquiv. (7.7M)\",\n",
    "    \"Caduceus-Ph\": \"Caduceus-Ph\\n(7.7M)\",\n",
    "    \"Caduceus-PS\": \"Caduceus-PS\\n(7.7M)\",\n",
    "    \"HyenaDNA\": \"HyenaDNA\\n(6.6M)\",\n",
    "    \"NTv2\": \"NTv2\\n(500M)\",\n",
    "    \"Enformer\": \"Enformer\\n(252M)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting changes to df\n",
    "df = pd.read_csv(osp.join(PATH_TO_OUTPUTS, \"SVM_results.csv\"), index_col=0)\n",
    "df_display = df.rename(columns={\"bucket_id\": \"Distance to TSS\"})\n",
    "df_display = df_display.replace({\"Distance to TSS\": {0: \"0 - 30k\", 1: \"30 - 100k\", 2: \"100k+\"}})\n",
    "df_display = df_display.replace({\"model_name\": model_name_replacement})\n",
    "\n",
    "# Take average over seeds\n",
    "df_display_selected = df_display.groupby(\n",
    "    [\"model_name\", \"Distance to TSS\", \"use_tissue\", \"C\"]\n",
    ").agg(AUROC=(\"AUROC\", np.mean)).reset_index()\n",
    "\n",
    "# Select best hyperparam by model/bucket\n",
    "best_ids = df_display_selected.groupby([\"model_name\", \"Distance to TSS\"])[\"AUROC\"].idxmax()\n",
    "df_display_selected = df_display_selected.loc[best_ids.reset_index()[\"AUROC\"].values]\n",
    "display(\n",
    "    df_display_selected.pivot(\n",
    "        index=\"model_name\", columns=\"Distance to TSS\", values=\"AUROC\"\n",
    "    )[[\"0 - 30k\", \"30 - 100k\", \"100k+\"]]\n",
    ")\n",
    "display(df_display_selected[[\"model_name\", \"Distance to TSS\", \"C\", \"use_tissue\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter results to selected hyperparams\n",
    "df_plot = pd.merge(\n",
    "    df_display, df_display_selected,\n",
    "    on=[\"model_name\", \"Distance to TSS\", \"use_tissue\", \"C\"]\n",
    ").drop(columns=[\"AUROC_y\"]).rename(columns={\"AUROC_x\": \"AUROC\"})\n",
    "\n",
    "# Plot results by distance to TSS\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.catplot(\n",
    "    data=df_plot,\n",
    "    x=\"model_name\",\n",
    "    y=\"AUROC\",\n",
    "    col=\"Distance to TSS\",\n",
    "    hue=\"Distance to TSS\",\n",
    "    kind=\"bar\",\n",
    "    errorbar=\"sd\",\n",
    "    height=12,\n",
    "    aspect=1,\n",
    "    dodge=False,\n",
    "    order=list(model_name_replacement.values()),\n",
    ")\n",
    "g.set_xticklabels(rotation=60, fontsize=30)\n",
    "g.set(xlabel=\"\")\n",
    "g.set(ylim=(0.4, 0.7))\n",
    "g.set_titles(template=\"Dist. to TSS: {col_name}\", fontsize=40)\n",
    "g.fig.suptitle(\"Predicting Effects of Variants on Gene Expression\", y=1.1, fontsize=40)\n",
    "g._legend.remove()\n",
    "# Display bar values\n",
    "# (See: https://stackoverflow.com/questions/55586912/seaborn-catplot-set-values-over-the-bars)\n",
    "for ax in tqdm(g.axes.ravel(), leave=False):\n",
    "    title = ax.title.get_text()\n",
    "    ax.set_title(title, fontsize=35)\n",
    "    for c in tqdm(ax.containers, leave=False):\n",
    "        labels = [f\"{v.get_height():0.3f}\" for v in c]\n",
    "        ax.bar_label(c, labels=labels, label_type=\"center\", color=\"white\", weight=\"bold\", fontsize=24)\n",
    "plt.show()\n",
    "g.savefig(osp.join(PATH_TO_OUTPUTS, \"SVM_results.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7858241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
